{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Steffi/tensorflow/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the data for the model\n",
    "A =  sio.loadmat('./HW2/A2P2.mat')['A']\n",
    "X = A[:,0:-1]\n",
    "Y = A[:,-1].reshape(10000,1)\n",
    "# Split the data into   90% and test 10%\n",
    "trainX,testx,trainY,testy = train_test_split(X,Y,test_size = 0.1)\n",
    "\n",
    "# Set model parameters\n",
    "num_features = trainX.shape[1] # num of input nodes\n",
    "num_labels = trainY.shape[1] # num of outcomes\n",
    "num_samples = trainX.shape[0] # 10000\n",
    "h_size = 5 # num hidden layers\n",
    "# Training parameters\n",
    "training_epochs = 10000\n",
    "n_hidden_1 = 100 # number of neurons layer_1\n",
    "n_hidden_2 = 80 # number of neurons layer_2\n",
    "n_hidden_3 = 50 # number of neurons layer_3\n",
    "n_hidden_4 = 10 # number of neurons layer_4\n",
    "n_hidden_5 = 1 # number of neurons layer_5\n",
    "\n",
    "# Interval for each print statement\n",
    "display_step = 500\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "# Learning rate of the network\n",
    "# learning_rate = tf.train.exponential_decay(learning_rate=0.01,\n",
    "#                                           global_step= global_step,\n",
    "#                                           decay_steps=num_samples,\n",
    "#                                           decay_rate= 0.95,\n",
    "#                                           staircase=False)\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Set the directory to specify where the summary will be written\n",
    "summaries_dir = \"./HW2/SummaryDir\" + datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "\n",
    "# pprint(trainX[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Placeholder values to hold values from trainX and trainY\n",
    "x_ = tf.placeholder(tf.float32,[None,num_features])\n",
    "y_ = tf.placeholder(tf.float32,[None,num_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function defines a five layered perceptron and with a sigmoid\n",
    "# activation for each hidden layer\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with sigmoid activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.sigmoid(layer_1)\n",
    "    \n",
    "    # Hidden layer with sigmoid activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.sigmoid(layer_2)\n",
    "    \n",
    "    # Hidden layer with sigmoid activation\n",
    "    layer_3 = tf.add(tf.matmul(layer_2,weights['h3']),biases['b3'])\n",
    "    layer_3 = tf.sigmoid(layer_3)\n",
    "    \n",
    "    # Hidden layer with sigmoid activation\n",
    "    layer_4 = tf.add(tf.matmul(layer_3,weights['h4']),biases['b4'])\n",
    "    layer_4 = tf.sigmoid(layer_4)\n",
    "     \n",
    "    # Hidden layer with sigmoid activation\n",
    "    layer_5 = tf.add(tf.matmul(layer_4,weights['h5']),biases['b5'])\n",
    "    layer_5 = tf.sigmoid(layer_5)\n",
    "#     Return layer_5 as the output layer of the neural network\n",
    "    return layer_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store layers' weight & biases, currently initialized as random normal \n",
    "# nummbers\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_features, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "    'h4': tf.Variable(tf.random_normal([n_hidden_3, n_hidden_4])),\n",
    "    'h5': tf.Variable(tf.random_normal([n_hidden_4, n_hidden_5])),\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'b4': tf.Variable(tf.random_normal([n_hidden_4])),\n",
    "    'b5': tf.Variable(tf.random_normal([n_hidden_5])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = multilayer_perceptron(x_, weights, biases)\n",
    "# Define loss and optimizer\n",
    "# Use a sigmoid loss function and GradientDescentOptimizer for the\n",
    "# optimizer\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, targets=y_))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "# Check training correctness\n",
    "correct_prediction = tf.equal(tf.round(pred),y_)\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Cost: 0.769487671, Accuracy: 0.4878\n",
      "Epoch: 500, Cost: 0.693425459, Accuracy: 0.5587\n",
      "Epoch: 1000, Cost: 0.693284265, Accuracy: 0.5587\n",
      "Epoch: 1500, Cost: 0.692998490, Accuracy: 0.5587\n",
      "Epoch: 2000, Cost: 0.634441923, Accuracy: 0.7768\n",
      "Epoch: 2500, Cost: 0.588036466, Accuracy: 0.8610\n",
      "Epoch: 3000, Cost: 0.579018646, Accuracy: 0.8776\n",
      "Epoch: 3500, Cost: 0.575209681, Accuracy: 0.8829\n",
      "Epoch: 4000, Cost: 0.573128091, Accuracy: 0.8853\n",
      "Epoch: 4500, Cost: 0.571741788, Accuracy: 0.8873\n",
      "Epoch: 5000, Cost: 0.570734091, Accuracy: 0.8887\n",
      "Epoch: 5500, Cost: 0.569979316, Accuracy: 0.8901\n",
      "Epoch: 6000, Cost: 0.569396356, Accuracy: 0.8908\n",
      "Epoch: 6500, Cost: 0.568931543, Accuracy: 0.8916\n",
      "Epoch: 7000, Cost: 0.568548781, Accuracy: 0.8919\n",
      "Epoch: 7500, Cost: 0.568225133, Accuracy: 0.8923\n",
      "Epoch: 8000, Cost: 0.567946589, Accuracy: 0.8928\n",
      "Epoch: 8500, Cost: 0.567706405, Accuracy: 0.8931\n",
      "Epoch: 9000, Cost: 0.567498373, Accuracy: 0.8933\n",
      "Epoch: 9500, Cost: 0.567317763, Accuracy: 0.8937\n",
      "Done with training!!!\n",
      "final cost on test set: 0.875\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "import timeit\n",
    "# def runFnc():\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        batch_sz=100\n",
    "        accr = []\n",
    "    #   data size\n",
    "        total_len=np.shape(trainX)[0]\n",
    "    # total_batch for cost calculation\n",
    "        total_batch = int(total_len/batch_sz)\n",
    "        for i in xrange(0,total_len,batch_sz):\n",
    "    # record the accuracy and average cost at each epoch\n",
    "            acc,_,c = sess.run([accuracy,optimizer,cost],\\\n",
    "                               feed_dict={x_:trainX[i:i+batch_sz],\\\n",
    "                                          y_:trainY[i:i+batch_sz]})\n",
    "            avg_cost += c/total_batch\n",
    "            accr.append(acc)\n",
    "        acc = np.mean(accr)\n",
    "    #  print out the epoch, cost and accuracy after every 500 iterations\n",
    "        if epoch % display_step == 0:\n",
    "            print('Epoch: {0}, Cost: {1:.9f}, Accuracy: {2:.4f}'.format(epoch,avg_cost,acc))\n",
    "    print(\"Done with training!!!\")\n",
    "    #Evaluate performance with the test data\n",
    "    print(\"final cost on test set: %s\" %str(sess.run(accuracy, feed_dict={x_:testx, y_:testy})))\n",
    "# timeit.timeit(runFnc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb = trainY[i:i+batch_sz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close the session and exit\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
